import streamlit as st
import pandas as pd
import subprocess
import os
import sys
import time
from datetime import datetime

# --- CONFIGURATION ---
st.set_page_config(
    page_title="Plouf Scraper",
    page_icon="ü§ñ",
    layout="wide"
)

# Dossiers et fichiers
SCRAPPING_DIR = os.path.dirname(os.path.abspath(__file__))
MOTS_CLES_CSV = os.path.join(SCRAPPING_DIR, "mots_cles.csv")
RESULTATS_DIR_RAW = os.path.join(SCRAPPING_DIR, "resultats")
RESULTATS_DIR_ENRICHED = os.path.join(SCRAPPING_DIR, "resultats_enrichis")
FICHIER_RAW = os.path.join(RESULTATS_DIR_RAW, "resultats_complets.csv")
FICHIER_ENRICHI = os.path.join(RESULTATS_DIR_ENRICHED, "resultats_enrichis_complets.csv")

# Styles CSS
st.markdown("""
<style>
    .stApp {
        background-color: #0e1117;
    }
    .stButton>button {
        width: 100%;
        border-radius: 5px;
        height: 3em;
        background-color: #ff4b4b;
        color: white;
        font-weight: bold;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 10px;
    }
    .stTabs [data-baseweb="tab"] {
        padding: 10px 20px;
        font-size: 1.1rem;
    }
</style>
""", unsafe_allow_html=True)

st.title("ü§ñ Plouf Scraper NextGen")

# --- SIDEBAR ---
with st.sidebar:
    st.header("‚öôÔ∏è Param√®tres")
    max_fiches = st.slider("Max fiches par recherche", 5, 100, 20)
    browser_type = st.radio("Navigateur √† utiliser", ["Firefox", "Chrome"], index=0)
    st.divider()
    if st.button("üßπ Effacer toutes les donn√©es"):
        for d in [RESULTATS_DIR_RAW, RESULTATS_DIR_ENRICHED]:
            if os.path.exists(d):
                import shutil
                shutil.rmtree(d)
        st.success("Toutes les donn√©es ont √©t√© effac√©es.")
        st.rerun()

# --- TABS ---
tab_launch, tab_results = st.tabs(["üöÄ Lancer la Prospection", "üìä Voir les R√©sultats"])

# --- TAB 1: LAUNCH ---
with tab_launch:
    col1, col2 = st.columns(2)
    with col1:
        keyword = st.text_input("üíé Quel type d'entreprise ?", placeholder="Ex: Restaurant, Coworking, Plombier...")
    with col2:
        zipcode = st.text_input("üìç Dans quel secteur ?", placeholder="Ex: 69000, Lyon...")

    st.markdown("---")
    st.subheader("üìÅ Ou importer un fichier CSV (Batch)")
    uploaded_file = st.file_uploader("Upload d'un CSV (Colonnes 'Soci√©t√©s' et 'Codes')", type=["csv"])
    
    if uploaded_file is not None:
        try:
            # Lire tout en string pour garder les z√©ros des codes postaux (ex: 01000)
            df_upload = pd.read_csv(uploaded_file, sep=None, engine='python', dtype=str)
            st.write("Aper√ßu du fichier :")
            st.dataframe(df_upload.head())
            
            # Normalisation des noms de colonnes (enlever espaces, minuscules)
            df_upload.columns = [c.strip() for c in df_upload.columns]
            
            col_soc = next((c for c in df_upload.columns if 'soci√©t' in c.lower()), None)
            col_code = next((c for c in df_upload.columns if 'code' in c.lower()), None)
            
            if col_soc and col_code:
                st.success(f"Colonnes d√©tect√©es : '{col_soc}' et '{col_code}'")
                
                # Nettoyage et compl√©tion des codes postaux (Garder 5 chiffres)
                df_upload[col_code] = df_upload[col_code].astype(str).str.strip().str.zfill(5)
                df_upload[col_soc] = df_upload[col_soc].astype(str).str.strip()
                
                queries = (df_upload[col_soc] + " " + df_upload[col_code] + " FR").tolist()
                st.info(f"{len(queries)} mots-cl√©s pr√™ts √† √™tre trait√©s.")
            else:
                st.error("Colonnes 'Soci√©t√©s' et 'Codes' non trouv√©es. V√©rifiez l'en-t√™te de votre CSV.")
                queries = None
        except Exception as e:
            st.error(f"Erreur de lecture : {e}")
            queries = None
    else:
        queries = None

    col_btn1, col_btn2 = st.columns(2)
    
    with col_btn1:
        text_btn = "üîç D√©marrer le Scraping"
        if queries:
            text_btn = f"üîç Scraper les {len(queries)} soci√©t√©s du CSV"
        launch_scraping = st.button(text_btn)
    
    with col_btn2:
        launch_enrich = st.button("‚ú® Enrichir les donn√©es existantes (Emails/T√©l)")

    # LOGIC SCRAPING
    if launch_scraping:
        if not queries and (not keyword or not zipcode):
            st.error("Veuillez renseigner un mot-cl√© ET un secteur, ou uploader un CSV valide.")
        else:
            if not queries:
                query = f"{keyword} {zipcode} FR"
                pd.DataFrame({"mot_cle": [query]}).to_csv(MOTS_CLES_CSV, index=False)
                st.info(f"D√©marrage du scraping (**{browser_type}**) pour : **{query}**")
            else:
                pd.DataFrame({"mot_cle": queries}).to_csv(MOTS_CLES_CSV, index=False)
                st.info(f"D√©marrage du scraping (**{browser_type}**) pour **{len(queries)}** recherches...")
            
            script = "scraper.py" if browser_type == "Firefox" else "scraper_chrome.py"
            pbar = st.progress(0)
            status = st.empty()
            log_container = st.empty()
            
            try:
                process = subprocess.Popen(
                    ["uv", "run", "python", "-u", script, str(max_fiches)],
                    cwd=SCRAPPING_DIR,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.STDOUT,
                    text=True,
                    bufsize=1
                )
                
                full_logs = ""
                while True:
                    line = process.stdout.readline()
                    if not line and process.poll() is not None: break
                    if line:
                        full_logs += line
                        log_container.code("\n".join(full_logs.splitlines()[-15:]))
                        
                        if "üîç Traitement du mot-cl√©" in line:
                            try:
                                # Extraire "1/14" et le mot-cl√©
                                parts = line.split(":")
                                current_info = parts[0].split(" ")[3] # "1/14"
                                current_keyword = parts[1].strip()
                                status.markdown(f"üöÄ Recherche **{current_info}** : **{current_keyword}**")
                                # Calculer un progr√®s approximatif
                                current_idx, total_idx = map(int, current_info.split("/"))
                                pbar.progress(current_idx / total_idx)
                            except:
                                pass
                        elif "üåÄ Scroll" in line: status.text("Maps: d√©filement et collecte...")
                        elif "| ‚úÖ" in line: status.text("Maps: extraction d'une fiche...")
                        elif "Enrichissement" in line: pbar.progress(95); status.text("Lancement de l'enrichissement...")

                process.wait()
                pbar.progress(100)
                if process.returncode == 0:
                    st.success("Scraping termin√© !")
                    st.balloons()
                else:
                    st.error(f"Erreur script (Code {process.returncode})")
            except Exception as e:
                st.error(f"Frayeur technique : {e}")

    # LOGIC ENRICHMENT
    if launch_enrich:
        if not os.path.exists(FICHIER_RAW):
            st.warning("Aucune donn√©e brute √† enrichir. Lancez d'abord un scraping.")
        else:
            script_enrich = "enrichisseur.py" if browser_type == "Firefox" else "enrichisseur_chrome.py"
            st.info("Lancement de l'enrichissement des donn√©es via les sites web...")
            pbar = st.progress(0)
            log_container = st.empty()
            
            try:
                process = subprocess.Popen(
                    ["uv", "run", "python", "-u", script_enrich],
                    cwd=SCRAPPING_DIR,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.STDOUT,
                    text=True,
                    bufsize=1
                )
                
                full_logs = ""
                while True:
                    line = process.stdout.readline()
                    if not line and process.poll() is not None: break
                    if line:
                        full_logs += line
                        log_container.code("\n".join(full_logs.splitlines()[-15:]))
                        pbar.progress(50) # Simple progress for enrich

                process.wait()
                pbar.progress(100)
                if process.returncode == 0:
                    st.success("Enrichissement termin√© !")
                    st.rerun()
                else:
                    st.error("Erreur durant l'enrichissement.")
            except Exception as e:
                st.error(f"Erreur : {e}")

# --- TAB 2: RESULTS ---
with tab_results:
    st.subheader("üìã R√©capitulatif des prospects trouv√©s")
    
    file_to_show = ""
    if os.path.exists(FICHIER_ENRICHI):
        file_to_show = FICHIER_ENRICHI
        st.write("‚úÖ Donn√©es enrichies disponibles (avec Emails/Web)")
    elif os.path.exists(FICHIER_RAW):
        file_to_show = FICHIER_RAW
        st.write("‚ö†Ô∏è Uniquement des donn√©es brutes (pas encore enrichies)")
    
    if file_to_show:
        df = pd.read_csv(file_to_show)
        
        # Filtre rapide
        search = st.text_input("üîç Rechercher dans les r√©sultats", "")
        if search:
            df = df[df.apply(lambda row: row.astype(str).str.contains(search, case=False).any(), axis=1)]
        
        # Affichage avec liens cliquables
        st.dataframe(
            df, 
            use_container_width=True, 
            height=500,
            column_config={
                "Site web": st.column_config.LinkColumn("Site Web", display_text="üåê Visiter"),
                "Email trouv√©": st.column_config.LinkColumn("Email", display_text="üìß Envoyer")
            }
        )
        
        col_dl1, col_dl2 = st.columns(2)
        with col_dl1:
            csv = df.to_csv(index=False).encode('utf-8')
            st.download_button(
                "üì• T√©l√©charger le CSV",
                csv,
                f"scraped_prospects_{datetime.now().strftime('%Y%m%d')}.csv",
                "text/csv",
                use_container_width=True
            )
        with col_dl2:
            if st.button("üóëÔ∏è Vider cet historique", use_container_width=True):
                if os.path.exists(file_to_show): os.remove(file_to_show)
                st.rerun()
    else:
        st.info("Aucun r√©sultat pour le moment. Allez dans l'onglet 'Lancement' !")

    # --- DEBUG SECTION ---
    with st.expander("üõ†Ô∏è Diagnostics (Si 0 r√©sultats)"):
        debug_dir = os.path.join(RESULTATS_DIR_RAW, "debug")
        if os.path.exists(debug_dir):
            screenshots = sorted([f for f in os.listdir(debug_dir) if f.endswith(".png")], reverse=True)
            if screenshots:
                st.warning(f"Derni√®re capture d'√©cran de d√©bug ({screenshots[0]}) :")
                st.image(os.path.join(debug_dir, screenshots[0]))
                if st.button("üóëÔ∏è Effacer les captures de d√©bug"):
                    import shutil
                    shutil.rmtree(debug_dir)
                    os.makedirs(debug_dir)
                    st.rerun()
            else:
                st.write("Aucun fichier de d√©bug trouv√©.")
        else:
            st.write("Le dossier de d√©bug n'a pas encore √©t√© cr√©√©.")
