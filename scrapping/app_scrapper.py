import streamlit as st
import pandas as pd
import subprocess
import os
import sys
import time
from datetime import datetime

# Import du module de recherche de dirigeants
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
import recherche_dirigeants

# --- CONFIGURATION ---
st.set_page_config(
    page_title="Plouf Scraper",
    page_icon="ü§ñ",
    layout="wide"
)

# Dossiers et fichiers
SCRAPPING_DIR = os.path.dirname(os.path.abspath(__file__))
MOTS_CLES_CSV = os.path.join(SCRAPPING_DIR, "mots_cles.csv")
RESULTATS_DIR_RAW = os.path.join(SCRAPPING_DIR, "resultats")
RESULTATS_DIR_ENRICHED = os.path.join(SCRAPPING_DIR, "resultats_enrichis")
RESULTATS_DIR_DIRIGEANTS = os.path.join(SCRAPPING_DIR, "resultats_dirigeants")
FICHIER_RAW = os.path.join(RESULTATS_DIR_RAW, "resultats_complets.csv")
FICHIER_ENRICHI = os.path.join(RESULTATS_DIR_ENRICHED, "resultats_enrichis_complets.csv")
FICHIER_DIRIGEANTS = os.path.join(RESULTATS_DIR_DIRIGEANTS, "resultats_dirigeants.csv")

# Styles CSS
st.markdown("""
<style>
    .stApp {
        background-color: #0e1117;
    }
    .stButton>button {
        width: 100%;
        border-radius: 5px;
        height: 3em;
        background-color: #ff4b4b;
        color: white;
        font-weight: bold;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 10px;
    }
    .stTabs [data-baseweb="tab"] {
        padding: 10px 20px;
        font-size: 1.1rem;
    }
</style>
""", unsafe_allow_html=True)

st.title("ü§ñ Plouf Scraper NextGen")

# --- SIDEBAR ---
with st.sidebar:
    st.header("‚öôÔ∏è Param√®tres")
    max_fiches = st.slider("Max fiches par recherche", 5, 100, 20)
    browser_type = st.radio("Navigateur √† utiliser", ["Firefox", "Chrome"], index=0)
    st.divider()
    if st.button("üßπ Effacer toutes les donn√©es"):
        for d in [RESULTATS_DIR_RAW, RESULTATS_DIR_ENRICHED, RESULTATS_DIR_DIRIGEANTS]:
            if os.path.exists(d):
                import shutil
                shutil.rmtree(d)
        st.success("Toutes les donn√©es ont √©t√© effac√©es.")
        st.rerun()

# --- TABS ---
tab_launch, tab_results, tab_dirigeants, tab_consolidated = st.tabs([
    "üöÄ Lancer la Prospection", 
    "üìä Voir les R√©sultats",
    "üëî Rechercher les Dirigeants",
    "üéØ Vue Consolid√©e"
])

# --- TAB 1: LAUNCH ---
with tab_launch:
    col1, col2 = st.columns(2)
    with col1:
        keyword = st.text_input("üíé Quel type d'entreprise ?", placeholder="Ex: Restaurant, Coworking, Plombier...")
    with col2:
        zipcode = st.text_input("üìç Dans quel secteur ?", placeholder="Ex: 69000, Lyon...")

    st.markdown("---")
    st.subheader("üìÅ Ou importer un fichier CSV (Batch)")
    uploaded_file = st.file_uploader("Upload d'un CSV (Colonnes 'Soci√©t√©s' et 'Codes')", type=["csv"])
    
    if uploaded_file is not None:
        try:
            # Lire tout en string pour garder les z√©ros des codes postaux (ex: 01000)
            df_upload = pd.read_csv(uploaded_file, sep=None, engine='python', dtype=str)
            st.write("Aper√ßu du fichier :")
            st.dataframe(df_upload.head())
            
            # Normalisation des noms de colonnes (enlever espaces, minuscules)
            df_upload.columns = [c.strip() for c in df_upload.columns]
            
            col_soc = next((c for c in df_upload.columns if 'soci√©t' in c.lower()), None)
            col_code = next((c for c in df_upload.columns if 'code' in c.lower()), None)
            
            if col_soc and col_code:
                st.success(f"Colonnes d√©tect√©es : '{col_soc}' et '{col_code}'")
                
                # Nettoyage et compl√©tion des codes postaux (Garder 5 chiffres)
                df_upload[col_code] = df_upload[col_code].astype(str).str.strip().str.zfill(5)
                df_upload[col_soc] = df_upload[col_soc].astype(str).str.strip()
                
                queries = (df_upload[col_soc] + " " + df_upload[col_code] + " FR").tolist()
                st.info(f"{len(queries)} mots-cl√©s pr√™ts √† √™tre trait√©s.")
            else:
                st.error("Colonnes 'Soci√©t√©s' et 'Codes' non trouv√©es. V√©rifiez l'en-t√™te de votre CSV.")
                queries = None
        except Exception as e:
            st.error(f"Erreur de lecture : {e}")
            queries = None
    else:
        queries = None

    col_btn1, col_btn2 = st.columns(2)
    
    with col_btn1:
        text_btn = "üîç D√©marrer le Scraping"
        if queries:
            text_btn = f"üîç Scraper les {len(queries)} soci√©t√©s du CSV"
        launch_scraping = st.button(text_btn)
    
    with col_btn2:
        launch_enrich = st.button("‚ú® Enrichir les donn√©es existantes (Emails/T√©l)")

    # LOGIC SCRAPING
    if launch_scraping:
        if not queries and (not keyword or not zipcode):
            st.error("Veuillez renseigner un mot-cl√© ET un secteur, ou uploader un CSV valide.")
        else:
            if not queries:
                query = f"{keyword} {zipcode} FR"
                pd.DataFrame({"mot_cle": [query]}).to_csv(MOTS_CLES_CSV, index=False)
                st.info(f"D√©marrage du scraping (**{browser_type}**) pour : **{query}**")
            else:
                pd.DataFrame({"mot_cle": queries}).to_csv(MOTS_CLES_CSV, index=False)
                st.info(f"D√©marrage du scraping (**{browser_type}**) pour **{len(queries)}** recherches...")
            
            script = "scraper.py" if browser_type == "Firefox" else "scraper_chrome.py"
            pbar = st.progress(0)
            status = st.empty()
            log_container = st.empty()
            
            try:
                process = subprocess.Popen(
                    ["uv", "run", "python", "-u", script, str(max_fiches)],
                    cwd=SCRAPPING_DIR,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.STDOUT,
                    text=True,
                    bufsize=1
                )
                
                full_logs = ""
                while True:
                    line = process.stdout.readline()
                    if not line and process.poll() is not None: break
                    if line:
                        full_logs += line
                        log_container.code("\n".join(full_logs.splitlines()[-15:]))
                        
                        if "üîç Traitement du mot-cl√©" in line:
                            try:
                                # Extraire "1/14" et le mot-cl√©
                                parts = line.split(":")
                                current_info = parts[0].split(" ")[3] # "1/14"
                                current_keyword = parts[1].strip()
                                status.markdown(f"üöÄ Recherche **{current_info}** : **{current_keyword}**")
                                # Calculer un progr√®s approximatif
                                current_idx, total_idx = map(int, current_info.split("/"))
                                pbar.progress(current_idx / total_idx)
                            except:
                                pass
                        elif "üåÄ Scroll" in line: status.text("Maps: d√©filement et collecte...")
                        elif "| ‚úÖ" in line: status.text("Maps: extraction d'une fiche...")
                        elif "Enrichissement" in line: pbar.progress(95); status.text("Lancement de l'enrichissement...")

                process.wait()
                pbar.progress(100)
                if process.returncode == 0:
                    st.success("Scraping termin√© !")
                    st.balloons()
                else:
                    st.error(f"Erreur script (Code {process.returncode})")
            except Exception as e:
                st.error(f"Frayeur technique : {e}")

    # LOGIC ENRICHMENT
    if launch_enrich:
        if not os.path.exists(FICHIER_RAW):
            st.warning("Aucune donn√©e brute √† enrichir. Lancez d'abord un scraping.")
        else:
            script_enrich = "enrichisseur.py" if browser_type == "Firefox" else "enrichisseur_chrome.py"
            st.info("Lancement de l'enrichissement des donn√©es via les sites web...")
            pbar = st.progress(0)
            log_container = st.empty()
            
            try:
                process = subprocess.Popen(
                    ["uv", "run", "python", "-u", script_enrich],
                    cwd=SCRAPPING_DIR,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.STDOUT,
                    text=True,
                    bufsize=1
                )
                
                full_logs = ""
                while True:
                    line = process.stdout.readline()
                    if not line and process.poll() is not None: break
                    if line:
                        full_logs += line
                        log_container.code("\n".join(full_logs.splitlines()[-15:]))
                        pbar.progress(50) # Simple progress for enrich

                process.wait()
                pbar.progress(100)
                if process.returncode == 0:
                    st.success("Enrichissement termin√© !")
                    st.rerun()
                else:
                    st.error("Erreur durant l'enrichissement.")
            except Exception as e:
                st.error(f"Erreur : {e}")

# --- TAB 2: RESULTS ---
with tab_results:
    st.subheader("üìã R√©capitulatif des prospects trouv√©s")
    
    file_to_show = ""
    if os.path.exists(FICHIER_ENRICHI):
        file_to_show = FICHIER_ENRICHI
        st.write("‚úÖ Donn√©es enrichies disponibles (avec Emails/Web)")
    elif os.path.exists(FICHIER_RAW):
        file_to_show = FICHIER_RAW
        st.write("‚ö†Ô∏è Uniquement des donn√©es brutes (pas encore enrichies)")
    
    if file_to_show:
        df = pd.read_csv(file_to_show)
        
        # Filtre rapide
        search = st.text_input("üîç Rechercher dans les r√©sultats", "")
        if search:
            df = df[df.apply(lambda row: row.astype(str).str.contains(search, case=False).any(), axis=1)]
        
        # Affichage avec liens cliquables
        st.dataframe(
            df, 
            use_container_width=True, 
            height=500,
            column_config={
                "Site web": st.column_config.LinkColumn("Site Web", display_text="üåê Visiter"),
                "Email trouv√©": st.column_config.LinkColumn("Email", display_text="üìß Envoyer")
            }
        )
        
        col_dl1, col_dl2 = st.columns(2)
        with col_dl1:
            csv = df.to_csv(index=False).encode('utf-8')
            st.download_button(
                "üì• T√©l√©charger le CSV",
                csv,
                f"scraped_prospects_{datetime.now().strftime('%Y%m%d')}.csv",
                "text/csv",
                use_container_width=True
            )
        with col_dl2:
            if st.button("üóëÔ∏è Vider cet historique", use_container_width=True):
                if os.path.exists(file_to_show): os.remove(file_to_show)
                st.rerun()
    else:
        st.info("Aucun r√©sultat pour le moment. Allez dans l'onglet 'Lancement' !")

    # --- DEBUG SECTION ---
    with st.expander("üõ†Ô∏è Diagnostics (Si 0 r√©sultats)"):
        debug_dir = os.path.join(RESULTATS_DIR_RAW, "debug")
        if os.path.exists(debug_dir):
            screenshots = sorted([f for f in os.listdir(debug_dir) if f.endswith(".png")], reverse=True)
            if screenshots:
                st.warning(f"Derni√®re capture d'√©cran de d√©bug ({screenshots[0]}) :")
                st.image(os.path.join(debug_dir, screenshots[0]))
                if st.button("üóëÔ∏è Effacer les captures de d√©bug"):
                    import shutil
                    shutil.rmtree(debug_dir)
                    os.makedirs(debug_dir)
                    st.rerun()
            else:
                st.write("Aucun fichier de d√©bug trouv√©.")
        else:
            st.write("Le dossier de d√©bug n'a pas encore √©t√© cr√©√©.")

# --- TAB 3: DIRIGEANTS ---
with tab_dirigeants:
    st.subheader("üëî Recherche des Dirigeants et Contacts")
    st.markdown("Cette fonctionnalit√© utilise **4 APIs publiques** pour trouver les dirigeants de vos prospects.")
    
    # V√©rifier si on a des donn√©es enrichies
    if not os.path.exists(FICHIER_ENRICHI):
        st.warning("‚ö†Ô∏è Aucune donn√©e enrichie trouv√©e. Veuillez d'abord :")
        st.markdown("1. Lancer un **scraping** dans l'onglet 'Lancer la Prospection'")
        st.markdown("2. **Enrichir** les donn√©es avec le bouton d'enrichissement")
        st.info("Les donn√©es enrichies sont n√©cessaires pour extraire les dirigeants.")
    else:
        # Afficher un aper√ßu des donn√©es sources
        df_source = pd.read_csv(FICHIER_ENRICHI)
        st.success(f"‚úÖ {len(df_source)} entreprises pr√™tes √† √™tre analys√©es")
        
        with st.expander("üìã Aper√ßu des donn√©es sources"):
            st.dataframe(df_source.head(5), use_container_width=True)
        
        st.markdown("---")
        
        # Bouton de lancement
        col_btn, col_info = st.columns([1, 2])
        with col_btn:
            launch_dirigeants = st.button("üöÄ Lancer la recherche des dirigeants", use_container_width=True)
        with col_info:
            st.info("üîç Cascade de 4 APIs : Gouv ‚Üí Pappers ‚Üí Annuaire ‚Üí Scraping")
        
        # Lancement de la recherche
        if launch_dirigeants:
            progress_bar = st.progress(0)
            status_text = st.empty()
            log_area = st.empty()
            
            logs = []
            
            def progress_callback(current, total, message):
                if total > 0:
                    progress_bar.progress(current / total)
                status_text.markdown(f"**{message}**")
                logs.append(f"[{current}/{total}] {message}")
                log_area.code("\n".join(logs[-10:]))  # Afficher les 10 derniers logs
            
            try:
                start_time = time.time()
                success = recherche_dirigeants.process_file(
                    FICHIER_ENRICHI, 
                    FICHIER_DIRIGEANTS, 
                    progress_callback=progress_callback
                )
                
                duration = round(time.time() - start_time, 2)
                
                if success:
                    st.balloons()
                    st.success(f"‚úÖ Recherche termin√©e en {duration}s !")
                    st.rerun()
                else:
                    st.error("‚ùå Une erreur est survenue pendant le traitement.")
                    
            except Exception as e:
                st.error(f"Erreur critique : {e}")
        
        # Affichage des r√©sultats si disponibles
        if os.path.exists(FICHIER_DIRIGEANTS):
            st.markdown("---")
            st.subheader("üìä R√©sultats de la recherche")
            
            df_dirigeants = pd.read_csv(FICHIER_DIRIGEANTS)
            
            # Statistiques
            col_stat1, col_stat2, col_stat3 = st.columns(3)
            with col_stat1:
                total = len(df_dirigeants)
                st.metric("Total entreprises", total)
            with col_stat2:
                trouves = len(df_dirigeants[df_dirigeants['Status Recherche'] == 'Trouv√©'])
                st.metric("Dirigeants trouv√©s", trouves, f"{round(trouves/total*100)}%")
            with col_stat3:
                with_siret = len(df_dirigeants[df_dirigeants['SIRET'].notna() & (df_dirigeants['SIRET'] != '')])
                st.metric("Avec SIRET", with_siret)
            
            # Filtre de recherche
            search_dir = st.text_input("üîç Rechercher dans les r√©sultats", "", key="search_dirigeants")
            if search_dir:
                df_dirigeants = df_dirigeants[df_dirigeants.apply(
                    lambda row: row.astype(str).str.contains(search_dir, case=False).any(), axis=1
                )]
            
            # Affichage du tableau
            st.dataframe(
                df_dirigeants,
                use_container_width=True,
                height=500,
                column_config={
                    "Site web": st.column_config.LinkColumn(
                        "Site Web",
                        help="Site web de l'entreprise",
                        display_text="üåê Visiter"
                    ),
                    "Lien Pappers": st.column_config.LinkColumn(
                        "Pappers",
                        help="Cliquer pour voir la fiche compl√®te sur Pappers",
                        display_text="üîó Voir"
                    ),
                    "SIRET": st.column_config.TextColumn("SIRET", help="Num√©ro SIRET de l'entreprise"),
                    "Dirigeants": st.column_config.TextColumn("Dirigeants", help="Noms et fonctions des dirigeants"),
                    "Source": st.column_config.TextColumn("Source", help="API ayant trouv√© l'information")
                }
            )
            
            # T√©l√©chargement
            col_dl1, col_dl2, col_dl3 = st.columns(3)
            with col_dl1:
                csv_dirigeants = df_dirigeants.to_csv(index=False).encode('utf-8')
                st.download_button(
                    "üì• T√©l√©charger CSV complet",
                    csv_dirigeants,
                    f"dirigeants_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                    "text/csv",
                    use_container_width=True
                )
            with col_dl2:
                # Export uniquement les trouv√©s
                df_found = df_dirigeants[df_dirigeants['Status Recherche'] == 'Trouv√©']
                csv_found = df_found.to_csv(index=False).encode('utf-8')
                st.download_button(
                    "‚úÖ T√©l√©charger uniquement trouv√©s",
                    csv_found,
                    f"dirigeants_trouves_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                    "text/csv",
                    use_container_width=True
                )
            with col_dl3:
                if st.button("üóëÔ∏è Supprimer ces r√©sultats", use_container_width=True):
                    os.remove(FICHIER_DIRIGEANTS)
                    st.rerun()

# --- TAB 4: VUE CONSOLID√âE ---
with tab_consolidated:
    st.subheader("üéØ Vue Consolid√©e : Prospects + Dirigeants")
    st.markdown("Cette vue affiche la **base de donn√©es consolid√©e** (historique complet).")
    
    FICHIER_CONSOLIDE = os.path.join(SCRAPPING_DIR, "resultats_consolides", "base_prospects_finale.csv")
    SCRIPT_CONSOLIDATION = os.path.join(SCRAPPING_DIR, "consolidation_prospects.py")

    col_action, col_status = st.columns([1, 2])
    with col_action:
        if st.button("üîÑ Mettre √† jour la consolidation"):
             with st.spinner("Consolidation en cours..."):
                try:
                    process = subprocess.run(
                        ["uv", "run", "python", SCRIPT_CONSOLIDATION],
                        cwd=SCRAPPING_DIR,
                        capture_output=True,
                        text=True
                    )
                    if process.returncode == 0:
                        st.success("Consolidation termin√©e !")
                        st.code(process.stdout)
                        time.sleep(1)
                        st.rerun()
                    else:
                        st.error("Erreur lors de la consolidation")
                        st.code(process.stderr)
                except Exception as e:
                    st.error(f"Erreur : {e}")

    # V√©rifier si le fichier consolid√© existe
    if not os.path.exists(FICHIER_CONSOLIDE):
        st.warning("‚ö†Ô∏è Aucune base consolid√©e trouv√©e. Veuillez lancer la consolidation.")
    else:
        try:
            df_consolide = pd.read_csv(FICHIER_CONSOLIDE)
            
            # Mapping des colonnes pour correspondre √† l'affichage habituel
            # Base: Nom Entreprise,Activit√©,Dirigeant,Email,T√©l√©phone,T√©l√©phone Secondaire,Site Web,Adresse,Code Postal,Ville,SIRET,Date Cr√©ation,Lien Pappers
            column_mapping = {
                "Nom Entreprise": "Nom",
                "Email": "Email trouv√©",
                "Dirigeant": "Dirigeants",
                "Site Web": "Site web"
            }
            df_display = df_consolide.rename(columns=column_mapping)
            
            # Ajout colonnes manquantes pour √©viter erreurs si absentes
            for col in ["SIRET", "Lien Pappers", "T√©l√©phone"]:
                if col not in df_display.columns:
                    df_display[col] = ""

            st.success(f"‚úÖ {len(df_display)} prospects dans la base historique")
            
            # Statistiques en haut
            col_stat1, col_stat2, col_stat3, col_stat4 = st.columns(4)
            with col_stat1:
                total = len(df_display)
                st.metric("Total Prospects", total)
            with col_stat2:
                with_email = len(df_display[df_display['Email trouv√©'].notna() & (df_display['Email trouv√©'] != '')])
                st.metric("Avec Email", with_email, f"{round(with_email/total*100) if total > 0 else 0}%")
            with col_stat3:
                # On consid√®re qu'un dirigeant est 'trouv√©' s'il y a du texte dans la colonne
                with_dirigeants = len(df_display[df_display['Dirigeants'].notna() & (df_display['Dirigeants'] != '') & (df_display['Dirigeants'] != 'Non list√©')])
                st.metric("Avec Dirigeants", with_dirigeants, f"{round(with_dirigeants/total*100) if total > 0 else 0}%")
            with col_stat4:
                complete = len(df_display[
                    (df_display['Email trouv√©'].notna() & (df_display['Email trouv√©'] != '')) &
                    (df_display['Dirigeants'].notna() & (df_display['Dirigeants'] != ''))
                ])
                st.metric("Complets", complete, f"{round(complete/total*100) if total > 0 else 0}%")
            
            st.markdown("---")
            
            # Filtres
            col_filter1, col_filter2 = st.columns(2)
            with col_filter1:
                filter_option = st.selectbox(
                    "üîç Filtrer par",
                    ["Tous", "Avec Email uniquement", "Avec Dirigeants uniquement", "Complets (Email + Dirigeants)", "Incomplets"],
                    key="filter_consolidated_base"
                )
            with col_filter2:
                search_consolidated = st.text_input("üîé Rechercher", "", key="search_consolidated_base")
            
            # Application des filtres
            df_filtered = df_display.copy()
            
            if filter_option == "Avec Email uniquement":
                df_filtered = df_filtered[df_filtered['Email trouv√©'].notna() & (df_filtered['Email trouv√©'] != '')]
            elif filter_option == "Avec Dirigeants uniquement":
                df_filtered = df_filtered[df_filtered['Dirigeants'].notna() & (df_filtered['Dirigeants'] != '')]
            elif filter_option == "Complets (Email + Dirigeants)":
                df_filtered = df_filtered[
                    (df_filtered['Email trouv√©'].notna() & (df_filtered['Email trouv√©'] != '')) &
                    (df_filtered['Dirigeants'].notna() & (df_filtered['Dirigeants'] != ''))
                ]
            elif filter_option == "Incomplets":
                 df_filtered = df_filtered[
                    (df_filtered['Email trouv√©'].isna() | (df_filtered['Email trouv√©'] == '')) |
                    (df_filtered['Dirigeants'].isna() | (df_filtered['Dirigeants'] == ''))
                ]
            
            if search_consolidated:
                df_filtered = df_filtered[df_filtered.apply(
                    lambda row: row.astype(str).str.contains(search_consolidated, case=False).any(), axis=1
                )]
            
            st.info(f"üìä Affichage de **{len(df_filtered)}** prospects sur {total}")
            
            # Affichage du tableau consolid√©
            st.dataframe(
                df_filtered,
                use_container_width=True,
                height=600,
                column_config={
                    "Site web": st.column_config.LinkColumn(
                        "Site Web",
                        display_text="üåê Visiter"
                    ),
                    "Email trouv√©": st.column_config.LinkColumn(
                        "Email",
                        display_text="üìß Envoyer"
                    ),
                    "Lien Pappers": st.column_config.LinkColumn(
                        "Pappers",
                        display_text="üîó Voir"
                    ),
                    "T√©l√©phone": st.column_config.TextColumn("T√©l√©phone"),
                    "Dirigeants": st.column_config.TextColumn("Dirigeants"),
                    "SIRET": st.column_config.TextColumn("SIRET")
                }
            )
            
            # Export
            st.markdown("---")
            col_export1, col_export2 = st.columns(2)
            
            with col_export1:
                csv_all = df_filtered.to_csv(index=False).encode('utf-8')
                st.download_button(
                    "üì• T√©l√©charger la s√©lection",
                    csv_all,
                    f"prospects_base_finale_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                    "text/csv",
                    use_container_width=True
                )
            
            with col_export2:
                # Cr√©er un fichier optimis√© pour la prospection
                cols_voulues = ['Nom', 'T√©l√©phone', 'Email trouv√©', 'Site web', 'Adresse', 'SIRET', 'Dirigeants', 'Lien Pappers', 'Activit√©', 'Ville']
                # Garder seulement celles qui existent
                cols_presentes = [c for c in cols_voulues if c in df_filtered.columns]
                
                df_prospect = df_filtered[cols_presentes].copy()
                csv_prospect = df_prospect.to_csv(index=False).encode('utf-8')
                st.download_button(
                    "üéØ Export Prospection Optimis√©",
                    csv_prospect,
                    f"export_prospection_final_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                    "text/csv",
                    use_container_width=True
                )

        except Exception as e:
            st.error(f"Erreur de lecture du fichier consolid√© : {e}")
